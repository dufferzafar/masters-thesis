% 3.2 Test Bed for Experiments
% * Master / Slave architecture
%     * 3 generations?

% * Txn Generation
%     * Master used to send to all
%     * Separate script
%         * sendtoaddress
%         * Tried using jmeter
%         * sendmany

\newpage
\section{Testbed} \label{impl-testbed}

In this section we describe the implementation of a testbed that can be used to perform experiments on the Bitcoin blockchain. Some salient features of our testbed are:

\begin{itemize}
    \item Spawn a network of Bitcoin nodes running on a cluster of cloud-based virtual machines.
    \item Replace Proof-of-Work with a centralized control program that triggers Blockchain events like generation of blocks \& anchors.
    \item Emulate conditions that a real-world blockchain faces by genenrating a high throughput of transactions, introducing network latencies etc.
    \item Fine grained control over various parameters controlling the experiment.
    \item Process the logs generated by the Bitcoin nodes.
\end{itemize}

The Bitcoin Core code ships with a library (called \textit{TestFramework}) that can spawn a network of Bitcoin nodes; but all those nodes can only run on a single machine. We saw this as a limitation as it prevented us from scaling up our experiments to hundreds of nodes. 
To remedy this, we extended the library by adding the ability to run Bitcoin nodes on a remote virtual machine (using the SSH protocol.)

Though Bitcoin Core is written in C++, the \textit{TestFramework} library is written in Python. To be able to use the same codebase, we implemented our tested in Python (v3.7) as well. 
This allowed us to utilize the vast ecosystem of third-party libraries that Python has, some of which are: 

\begin{itemize}
    \item \textbf{paramiko} for connecting to remote machines using SSH.
    \item \textbf{socket, http.client} for estabilishing RPC connections to Bitcoin nodes.
    \item \textbf{json} for serializing the data being sent over the RPC connection.
    \item \textbf{random} for generating random events (like block or anchor generation etc.) that resembled an exponential probability distribution.
    \item \textbf{time} for "sleeping" between these events, instead of performing proof-of-work computation. 
\end{itemize}

%----------------------------------------------------------------------------------------

\newpage
\subsection{Centralized Controller} \label{impl-master}

The core part of the testbed is a centralized program (called "Master") that controls the entire experiment. We now explain the various tasks that the Master program performs.

% \vspace{0.5cm}

\subsubsection{Network Setup}

\begin{enumerate}
    \item The Master program begins by launching the Bitcoin processes on remote virtual machines (VMs) using SSH.
          This can be configured by specifying the IP addresses of the VMs and the number of Bitcoin nodes to launch on each VM.
          Each Bitcoin process locks up some system resources like the port numbers it listens on for RPC / Bitcoin protocol connections, and the "data-directory" it uses to store its local blockchain \& log files.
          To launch multiple Bitcoin processes on a single machine, we allocate a different set of such resources for each process by passing in arguments while launching the process.

    \item Once all the processes have been launched, a TCP/RPC connection is acquired to each one of them. 
          This connection is used to send RPC messages to the process to control its behaviour.

    \item By default, a Bitcoin process has no idea of the other ones running in the network, so the Master program then connects these processes into a network according to a predefined topology by sending \textit{addnode} RPC command.
          Further discussion of the network topology is deferred to Section \fixme{ref}.
\end{enumerate}
      
\subsubsection{Chain Setup \& Transaction Generation}

% Though real-world blockchains start their operation from a

\begin{enumerate}
    \item Once the nodes become aware of each other, the Master program generates empty blocks at each node so they have bitcoins to spend.
    
    \item These bitcoins are later used to generate transactions that are used to fill up the Blocks that are generated.
          Secction \fixme{ref} goes over this process in more detail.
\end{enumerate}

\subsubsection{Block \& Anchor Generation}

\begin{enumerate}
    \item While generating a Block or an Anchor the Master program avoids doing actual proof-of-work computation and instead simulates the mining process by randomly choosing a node as the creator of a Block (or Anchor) at random time instants.
    Since Block inter-arrival times in Bitcoin can be approximated by an exponential distribution \cite{bitcoinOriginal}, the random time instants are sampled from such a distribution with a predefined mean.
    The inter-arrival times between Anchors are sampled from another exponential distribution with a different mean.

    \item This process continues for a a predefined amount of time (called the "lifetime" of the experiment) after which Block \& Anchor generation is stopped.
\end{enumerate}

\subsubsection{Log Processing}

Each Bitcoin process logs all the events that happen on the node into a log file stored in the "data-directory".
% We added new log lines
Once the experiment finishes, the Master program fetches logs from all the nodes, extracts relevant information that is of use to us and generates a result file for the experiment which contains the various statistics that we measure. Refer to the \fixme{ref} for the results that are generated.

\subsubsection{Cleanup}

After the logs have been processed, the Master program stops all the running Bitcoin processes, deletes the data-directories and removes all manually introduced delays from the nodes so that the next experiment can start from a clean slate.

%----------------------------------------------------------------------------------------

\newpage
\subsection{Architecture} \label{impl-testbed-arch}

We went over different architectures for the testbed, starting with the most straightforward one, where the Master program handled bulk of the load during the experiments

\subsubsection{Iteration 1} \label{impl-arch-1}

We started with a simple

\begin{figure}[!htb]
    \centering
    \includegraphics[width=\textwidth]{"Arch v1".pdf}
    \caption{First iteration of Master's architecture}
    
    \medskip
    \footnotesize
    The "Master" program controls generation of Blocks, Anchors and Transactions.
    \label{fig-impl-arch-1}
\end{figure}

%----------------------------------------------------------------------------------------

\newpage
\subsubsection{Iteration 2} \label{impl-arch-1}

\begin{figure}[!htb]
    \centering
    \includegraphics[width=\textwidth]{"Arch v2".pdf}
    \caption{Second iteration of Master's architecture}
    
    \medskip
    \footnotesize
    Transaction generation thread has been moved to each VM to increase throughput.
    \label{fig-impl-arch-2}
\end{figure}

%----------------------------------------------------------------------------------------

\newpage
\subsubsection{Iteration 3} \label{impl-arch-3}

\begin{figure}[!htb]
    \centering
    \includegraphics[width=\textwidth]{"Arch v3".pdf}
    \caption{Third iteration of Master's architecture}
    
    \medskip
    \footnotesize
    Block \& Anchor generation threads have also been moved to each VM.
    \label{fig-impl-arch-3}
\end{figure}


%----------------------------------------------------------------------------------------

\newpage
\subsection{Transaction Throughput} \label{impl-testbed-arch}

%----------------------------------------------------------------------------------------

\begin{itemize}

    \item Master used to send to all
    \item sendtoaddress
    \item jmeter
    \item sendmany

\end{itemize}
